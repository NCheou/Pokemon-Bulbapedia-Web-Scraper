{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fcb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports requests.get, beautiful soup, manipulating csvs, os for current path, and re for regular expressions\n",
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55a4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishes a base URL that we then append new pokemon links to. \n",
    "rootURL = \"https://bulbapedia.bulbagarden.net\"\n",
    "#The indexURL starts at Miraidon that's the most recent pokemon, so after this it loops back to Bulbasaur. \n",
    "indexURL = rootURL + '/wiki/Miraidon_(Pokémon)'\n",
    "#Creates an empty list to append pokemon stats to\n",
    "allPokemonData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c651fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the location of the CSV we are writing to. Currently, it requires an existing CSV named Pokemonstats \n",
    "#As it was easier to do.\n",
    "csv_file = currentPath + '\\Pokemonstats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87cc309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the names of the columsn in the CSV\n",
    "csv_columns = ['National Dex Number', 'Name', 'Type 1', 'Type 2', 'HP', 'Attack', 'Defense', 'Sp. Attack', 'Sp. Defense', 'Speed', 'Stat Total', 'Weight (kg)', 'Height (m)', 'Generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1723c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a function to get the URL for the next pokemon. It finds 'Name_(Pokemon)' and appends it to the\n",
    "#rootURL to create a the URL for the next pokemon. It does this 1006 times as that's how many pokemon there are. \n",
    "#It would need to be updated when new pokemon are released. \n",
    "#We use yield here because if you use return, it breaks a while loop.\n",
    "def getPokemonURLs():\n",
    "    soup = bs4.BeautifulSoup(requests.get(indexURL).content, 'html.parser')\n",
    "    next_pokemon_url_table = soup.find_all('td', style='text-align: left')[0].find('a', href=True)['href']\n",
    "    #new_URL = next_pokemon_url_table[0].find('a', href=True)['href']\n",
    "    next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + next_pokemon_url_table\n",
    "    count = 0    \n",
    "    yield(next_pokemon_url)\n",
    "    while count <1007:\n",
    "        next_pokemon_url_table = bs4.BeautifulSoup(requests.get(next_pokemon_url).content, 'html.parser').find_all('td', style='text-align: left')[0].find('a', href=True)['href']\n",
    "        #new_URL = next_pokemon_url_table[0].find('a', href=True)['href'][0].find('a', href=True)['href']\n",
    "        next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + next_pokemon_url_table\n",
    "        yield(next_pokemon_url)\n",
    "        count += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007125f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes a pokemon URL and scrapes all the data we want. We start with a list consisting of 14 zeroes, then we \n",
    "#replace each zero with the info we want.\n",
    "def getPokemonData(inputURL):\n",
    "    pokemonData = [0]*14 \n",
    "    #htmlData    = requests.get( rootURL + inputURL)\n",
    "    #this line seems to do https://bulbapedia.bulbagarden.net + https://bulbapedia.bulbagarden.net/wiki/Ivysaur_(Pokémon). \n",
    "    #we want only the full link\n",
    "    htmlData  = requests.get(inputURL)\n",
    "    soup      = bs4.BeautifulSoup(htmlData.text, \"html.parser\" )\n",
    "    #These next two lines are for finding the generation of the pokemon\n",
    "    name_soup = soup.select('ul li span a[class*=\"external text\"]')\n",
    "    name_soup = bs4.BeautifulSoup(str(name_soup)).get_text()\n",
    "    \n",
    "    #This looks for the national dex number. Unfortunately at this time, the national dex numbers for \n",
    "    #generation 9 have not been updated yet, so they were manually put in.\n",
    "    pokemonData[0] = soup.th.big.a.span.text\n",
    "    \n",
    "    #This returns the name of the pokemon, and gets rid of all special characters.\n",
    "    #Nidoran gave me issues because its name has a gender symbol in it, and I couldn't\n",
    "    #write that symbol to a csv\n",
    "    pokemonData[1] = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", (soup.select('h1#firstHeading')[0].get_text())[:-10])\n",
    "    \n",
    "    #This looks for the a class that contains the type and gets the first element\n",
    "    pokemonData[2] = soup.select('td a[href*=\"(type)\"] span b')[0].get_text()\n",
    "    \n",
    "    #Some pokemon have two typings, so what this does is it gets [1] and if the\n",
    "    #pokemon doesn't have a second type, it will return 'Unknown'. If it returns\n",
    "    #that, it will copy the mono type over to the Type 2 column. \n",
    "    if soup.select('a[href*=\"(type)\"] span b')[1].get_text() != 'Unknown':\n",
    "        pokemonData[3] = soup.select('td[width = \"45px\"] a[href*=\"(type)\"] span b')[1].get_text()\n",
    "    if soup.select('a[href*=\"(type)\"] span b')[1].get_text() == 'Unknown':\n",
    "        pokemonData[3] = soup.select('td a[href*=\"(type)\"] span b')[0].get_text()\n",
    "    #This finds the div class with style 'float:right' which only appears on the base stats table\n",
    "    #The first element corresponds to HP, Attack, etc and then transforms it into an integer\n",
    "    pokemonData[4] = (int)(soup.find_all('div', attrs={'style':'float:right'})[0].get_text())\n",
    "    pokemonData[5] = (int)(soup.find_all('div', attrs={'style':'float:right'})[1].get_text())\n",
    "    pokemonData[6] = (int)(soup.find_all('div', attrs={'style':'float:right'})[2].get_text())\n",
    "    pokemonData[7] = (int)(soup.find_all('div', attrs={'style':'float:right'})[3].get_text())\n",
    "    pokemonData[8] = (int)(soup.find_all('div', attrs={'style':'float:right'})[4].get_text())\n",
    "    pokemonData[9] = (int)(soup.find_all('div', attrs={'style':'float:right'})[5].get_text())\n",
    "    pokemonData[10] = (int)(soup.find_all('div', attrs={'style':'float:right'})[6].get_text())\n",
    "    \n",
    "    #This looks for the weight of the pokemon in kilograms. It does this by finding the a href title:Weight\n",
    "    #Then going up two levels with .parent.parent. then it finds the first 'td' under it, which contains \n",
    "    #two elements. [0] is in pounds, [1] is in kg. I chose to .split() to get only the float\n",
    "    #because otherwise it would report 1 kg instead of just 1.\n",
    "    pokemonData[11] = (float)(soup.find('a', {'title': 'Weight'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "    pokemonData[12] = (float)(soup.find('a', {'title': 'List of Pokémon by height'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "    #This line finds the generation by going to the list of generations the pokemon appears in and finding the first one\n",
    "    #For some reason, the wiki uses a different format for generations 8 and 9, so this doesn't get the generation\n",
    "    #for those pokemon. Those were input manually, but it's fairly easy. \n",
    "    pokemonData[13] = name_soup[:-1][1:].split(',')[0]\n",
    "    \n",
    "    allPokemonData.append(pokemonData)\n",
    "    #print(allPokemonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e8db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the list of pokemon URLs generated and scrapes the stats from the first URL\n",
    "#then iterates through the rest of them until it's finished. \n",
    "def allPokemonStats():\n",
    "    pokemonURLs = getPokemonURLs()\n",
    "    #counter = 0\n",
    "    #while counter < 1007:    \n",
    "    for pokemonURL in pokemonURLs:\n",
    "        getPokemonData(pokemonURL)\n",
    "        #counter += 1\n",
    "    #print(allPokemonData)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65734ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This writes to an existing CSV\n",
    "def WriteListToCSV(csv_file, csv_columns, data_list):\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(csv_columns) #include if you want to have the csv column names too\n",
    "        for data in data_list:\n",
    "            writer.writerow(data)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes the pokemon stats function\n",
    "allPokemonStats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cfb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes CSV function\n",
    "WriteListToCSV( csv_file, csv_columns, allPokemonData )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
